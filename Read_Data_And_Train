import tensorflow as tf

import os

from tensorflow.contrib.boosted_trees.lib.learner import batch

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID";
os.environ["CUDA_VISIBLE_DEVICES"] = "0";

import os
import cv2
import pdb
import glob
# import argparse
import numpy as np
from keras.preprocessing.image import ImageDataGenerator

from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras import backend as K
from keras.callbacks import ModelCheckpoint

from PIL import ImageFile

from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add
from keras.models import Model, model_from_json
from keras.optimizers import Adam
from keras.layers.advanced_activations import ELU, LeakyReLU
from keras.utils.vis_utils import plot_model
from keras import backend as K


def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):

    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)
    x = BatchNormalization(axis=3, scale=False)(x)
    if (activation == None):
        return x
    x = Activation(activation, name=name)(x)
    return x


def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):
    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)
    x = BatchNormalization(axis=3, scale=False)(x)
    return x

def MultiResBlock(U, inp, alpha=1.67):
    W = alpha * U
    shortcut = inp
    shortcut = conv2d_bn(shortcut, int(W * 0.167) + int(W * 0.333) + int(W * 0.5), 1, 1, activation=None, padding='same')
    conv3x3 = conv2d_bn(inp, int(W * 0.167), 3, 3, activation='relu', padding='same')
    conv5x5 = conv2d_bn(conv3x3, int(W * 0.333), 3, 3, activation='relu', padding='same')
    conv7x7 = conv2d_bn(conv5x5, int(W * 0.5), 3, 3, activation='relu', padding='same')
    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)
    out = BatchNormalization(axis=3)(out)
    out = add([shortcut, out])
    out = Activation('relu')(out)
    out = BatchNormalization(axis=3)(out)
    return out

def ResPath(filters, length, inp):

    shortcut = inp
    shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')
    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')
    out = add([shortcut, out])
    out = Activation('relu')(out)
    out = BatchNormalization(axis=3)(out)

    for i in range(length - 1):
        shortcut = out
        shortcut = conv2d_bn(shortcut, filters, 1, 1,activation=None, padding='same')
        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')
        out = add([shortcut, out])
        out = Activation('relu')(out)
        out = BatchNormalization(axis=3)(out)
    return out

def dice_coef(y_true, y_pred, smooth=1.0):
    class_num = 1  # it could be 2
    for i in range(class_num):
        y_true_f = K.flatten(y_true[:, :, :, i])
        y_pred_f = K.flatten(y_pred[:, :, :, i])
        intersection = K.sum(y_true_f * y_pred_f)
        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))
        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
    total_loss = total_loss / class_num
    return total_loss


def dice_coef_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

def MultiResUnet(height, width, n_channels):

    inputs = Input((height, width, n_channels))

    mresblock1 = MultiResBlock(32, inputs)
    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)
    mresblock1 = ResPath(32, 4, mresblock1)

    mresblock2 = MultiResBlock(32 * 2, pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)
    mresblock2 = ResPath(32 * 2, 3, mresblock2)

    mresblock3 = MultiResBlock(32 * 4, pool2)
    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)
    mresblock3 = ResPath(32 * 4, 2, mresblock3)

    mresblock4 = MultiResBlock(32 * 8, pool3)
    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)
    mresblock4 = ResPath(32 * 8, 1, mresblock4)

    mresblock5 = MultiResBlock(32 * 16, pool4)

    up6 = concatenate([Conv2DTranspose(32 * 8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)
    mresblock6 = MultiResBlock(32 * 8, up6)

    up7 = concatenate([Conv2DTranspose(32 * 4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)
    mresblock7 = MultiResBlock(32 * 4, up7)

    up8 = concatenate([Conv2DTranspose(32 * 2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)
    mresblock8 = MultiResBlock(32 * 2, up8)

    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock8), mresblock1], axis=3)
    mresblock9 = MultiResBlock(32, up9)

    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')

    model = Model(inputs=[inputs], outputs=[conv10])

    model.compile(optimizer=Adam(lr=0.001, decay=0.001), loss=dice_coef_loss, metrics=[dice_coef])

    return model

n_conv = 8

def MultiRes_litnet(inputs):

    mresblock1 = MultiResBlock(n_conv, inputs)
    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)
    mresblock1 = ResPath(n_conv, 4, mresblock1)

    mresblock2 = MultiResBlock(n_conv * 2, pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)
    mresblock2 = ResPath(n_conv * 2, 3, mresblock2)

    mresblock3 = MultiResBlock(n_conv * 4, pool2)
    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)
    mresblock3 = ResPath(n_conv * 4, 2, mresblock3)

    mresblock4 = MultiResBlock(n_conv * 8, pool3)
    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)
    mresblock4 = ResPath(n_conv * 8, 1, mresblock4)

    mresblock5 = MultiResBlock(n_conv * 16, pool4)

    up6 = concatenate([Conv2DTranspose(n_conv * 8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)
    mresblock6 = MultiResBlock(n_conv * 8, up6)

    up7 = concatenate([Conv2DTranspose(n_conv * 4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)
    mresblock7 = MultiResBlock(n_conv * 4, up7)

    up8 = concatenate([Conv2DTranspose(n_conv * 2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)
    mresblock8 = MultiResBlock(n_conv * 2, up8)

    up9 = concatenate([Conv2DTranspose(n_conv, (2, 2), strides=(2, 2), padding='same')(mresblock8), mresblock1], axis=3)
    mresblock9 = MultiResBlock(n_conv, up9)

    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')

    model = Model(inputs=[inputs], outputs=[conv10])

    model.compile(optimizer=Adam(lr=0.01, decay=0.00000001), loss=dice_coef_loss, metrics=[dice_coef])

    return model

ImageFile.LOAD_TRUNCATED_IMAGES = True

%cd ../

all_files = glob.glob('content/meiimgs/*.bmp')

resume = True
batch_siz = 64
# l_r=.0000015  # somthing between 0.000009 and 0.0000003
l_r=.00009  # somthing between 0.000009 and 0.0000003
dec = 0
epoch =1000
data='complete'

%cd content

image_root = '/content/'
image_folder='meiimgs'
mask_folder='meimsks'

val_image_folder='valimgs'
val_mask_folder='valmsks'
# ckpt_path='PL_1.h5'
img_H = 240
img_W = 240
steps___per_epochs = np.ceil(len(all_files)/batch_siz)

# def dice_coef(y_true, y_pred, smooth=1.0):

#     class_num = 1 # it could be 2
#     for i in range(class_num):
#         y_true_f = K.flatten(y_true[:,:,:,i])
#         y_pred_f = K.flatten(y_pred[:,:,:,i])
#         intersection = K.sum(y_true_f * y_pred_f)
#         loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))
#         if i == 0:
#             total_loss = loss
#         else:
#             total_loss = total_loss + loss
#     total_loss = total_loss / class_num
#     return total_loss

# def dice_coef_loss(y_true, y_pred):
#     return 1-dice_coef(y_true, y_pred)

ker = 3
n_conv = 4

def u_net(input):

    conv1 = Conv2D(n_conv, (ker, ker), padding='same') (input)
    conv1 = Conv2D(n_conv, (ker, ker), padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    pool1 = BatchNormalization()(pool1)

    conv2 = Conv2D(n_conv*2, (ker, ker), padding='same')(pool1)
    conv2 = Conv2D(n_conv*2, (ker, ker), padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    pool2 = BatchNormalization()(pool2)

    conv3 = Conv2D(n_conv*4, (ker, ker), padding='same')(pool2)
    conv3 = Conv2D(n_conv*4, (ker, ker), padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    pool3 = BatchNormalization()(pool3)

    conv4 = Conv2D(n_conv*8, (ker, ker), padding='same')(pool3)
    conv4 = Conv2D(n_conv*8, (ker, ker), padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    pool4 = BatchNormalization()(pool4)

    conv5 = Conv2D(n_conv*16, (ker, ker), padding='same')(pool4)
    conv5 = Conv2D(n_conv*16, (ker, ker), padding='same')(conv5)
    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)
    conv5 = BatchNormalization()(pool5)

    conv55 = Conv2D(n_conv*32, (ker, ker), padding='same')(pool5)
    conv55 = Conv2D(n_conv*32, (ker, ker), padding='same')(conv55)
    conv55 = BatchNormalization()(conv55)

    up56 = concatenate([Conv2DTranspose(n_conv*16, (2, 2), strides=(2, 2), padding='same')(conv55),conv5], axis=3)
    up56 = BatchNormalization()(up56)
    up56 = Dropout(0.5)(up56)

    conv56 = Conv2D(n_conv*16, (ker, ker), padding='same')(up56)
    conv56 = Conv2D(n_conv*16, (ker, ker), padding='same')(conv56)
    conv56 = BatchNormalization()(conv56)

    up6 = concatenate([Conv2DTranspose(n_conv*8, (2, 2), strides=(2, 2), padding='same')(conv56),conv4], axis=3)
    up6 = BatchNormalization()(up6)
    up6 = Dropout(0.5)(up6)

    conv6 = Conv2D(n_conv*8, (ker, ker), padding='same')(up6)
    conv6 = Conv2D(n_conv*8, (ker, ker), padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)
    
    up7 = concatenate([Conv2DTranspose(n_conv*4, (2, 2), strides=(2, 2), padding='same')(conv6),conv3], axis=3)
    up7 = BatchNormalization()(up7)
    up7 = Dropout(0.5)(up7)

    conv7 = Conv2D(n_conv*4, (ker, ker), padding='same')(up7)
    conv7 = Conv2D(n_conv*4, (ker, ker), padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)
    
    up8 = concatenate([Conv2DTranspose(n_conv*2, (2, 2), strides=(2, 2),padding='same')(conv7),conv2], axis=3)
    up8 = BatchNormalization()(up8)
    up8 = Dropout(0.5)(up8)

    conv8 = Conv2D(n_conv*2, (ker, ker), padding='same')(up8)
    conv8 = Conv2D(n_conv*2, (ker, ker), padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)

    up9 = concatenate([Conv2DTranspose(n_conv, (2, 2), strides=(2, 2), padding='same')(conv8),conv1], axis=3)
    up9 = BatchNormalization()(up9)
    up9 = Dropout(0.5)(up9)

    conv9 = Conv2D(n_conv, (ker, ker), padding='same')(up9)
    conv9 = Conv2D(n_conv, (ker, ker), padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)
    
    conv9 = GaussianNoise(1.0)(conv9)
    
    conv10 = Conv2D(2, (1, 1), activation='softmax')(conv9)

    model = Model(inputs=[input], outputs=[conv10])

    model.compile(optimizer=Adam(lr=0.001, decay=0.001), loss=dice_coef_loss, metrics=[dice_coef])
    
    return model


def lit_net(input):

    conv1 = Conv2D(n_conv, (ker, ker), padding='same') (input)
    conv1 = Conv2D(n_conv, (ker, ker), padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    pool1 = BatchNormalization()(pool1)

    conv2 = Conv2D(n_conv*2, (ker, ker), padding='same')(pool1)
    conv2 = Conv2D(n_conv*2, (ker, ker), padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    pool2 = BatchNormalization()(pool2)

    conv3 = Conv2D(n_conv*4, (ker, ker), padding='same')(pool2)
    conv3 = Conv2D(n_conv*4, (ker, ker), padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    pool3 = BatchNormalization()(pool3)

    conv4 = Conv2D(n_conv*8, (ker, ker), padding='same')(pool3)
    conv4 = Conv2D(n_conv*8, (ker, ker), padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)

    up6 = concatenate([Conv2DTranspose(n_conv*8, (2, 2), strides=(2, 2), padding='same')(conv4),conv3], axis=3)
    up6 = BatchNormalization()(up6)
    up6 = Dropout(0.5)(up6)

    conv7 = Conv2D(n_conv*4, (ker, ker), padding='same')(up6)
    conv7 = Conv2D(n_conv*4, (ker, ker), padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)
    
    up8 = concatenate([Conv2DTranspose(n_conv*2, (2, 2), strides=(2, 2),padding='same')(conv7),conv2], axis=3)
    up8 = BatchNormalization()(up8)
    up8 = Dropout(0.5)(up8)

    conv8 = Conv2D(n_conv*2, (ker, ker), padding='same')(up8)
    conv8 = Conv2D(n_conv*2, (ker, ker), padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)

    up9 = concatenate([Conv2DTranspose(n_conv, (2, 2), strides=(2, 2), padding='same')(conv8),conv1], axis=3)
    up9 = BatchNormalization()(up9)
    up9 = Dropout(0.5)(up9)

    conv9 = Conv2D(n_conv, (ker, ker), padding='same')(up9)
    conv9 = Conv2D(n_conv, (ker, ker), padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)
    
    conv9 = GaussianNoise(0.5)(conv9)
    
    conv10 = Conv2D(2, (1, 1), activation='softmax')(conv9)

    model = Model(inputs=[input], outputs=[conv10])

    model.compile(optimizer=Adam(lr=0.01, decay=0.001), loss=dice_coef_loss, metrics=[dice_coef])
    
    return model

def adjustData(img, label, data, cnt, val='F'):

    img = img / 255.0
    label[label < 25] = 0
    label[label >= 25] = 1

    return img, label

# grayscale or rgba

def dataset(mode='train',
            image_color_mode = "grayscale", label_color_mode = "grayscale",
            image_save_prefix  = "mei_imgs", label_save_prefix  = "mei_msks",
            save_to_dir = None, target_size = (img_H, img_W), seed = 1):  

    if mode == 'train':
        shuffle=True

#         image_datagen = ImageDataGenerator()

        image_datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=False,
                                           vertical_flip=False, width_shift_range=0.1, height_shift_range=0.1,
                                           zca_whitening = True , zca_epsilon = 0.0001)
#                                            shear_range=0.1,
#                                            zoom_range=0.1)
                                           #brightness_range=[0.8,1.2])

#         label_datagen = ImageDataGenerator()
        label_datagen = ImageDataGenerator(rotation_range=20,
                                           horizontal_flip=False,
                                           vertical_flip=False,
                                           width_shift_range=0.1,
                                           height_shift_range=0.1)
#                                            shear_range=0.1,
#                                            zoom_range=0.1)

    elif mode == 'test' or mode == 'valid':
        shuffle=True
        image_datagen = ImageDataGenerator()
        label_datagen = ImageDataGenerator()
    else:
        raise ValueError('dataset mode ERROR!')

    image_generator1 = image_datagen.flow_from_directory(
        image_root,
        classes = [image_save_prefix],
        class_mode = None,
        color_mode = image_color_mode,
        target_size = target_size,
        batch_size = batch_siz,
        save_to_dir = save_to_dir,
        save_prefix  = image_save_prefix,
        shuffle = shuffle,
        seed = seed)

    label_generator1 = label_datagen.flow_from_directory(
        image_root,
        classes = [label_save_prefix],
        class_mode = None,
        color_mode = label_color_mode,
        target_size = target_size,
        batch_size = batch_siz,
        save_to_dir = save_to_dir,
        save_prefix  = label_save_prefix,
        shuffle = shuffle,
        seed = seed)

    
    image_generator2 = image_datagen.flow_from_directory(
        image_root,
        classes = [val_image_folder],
        class_mode = None,
        color_mode = image_color_mode,
        target_size = target_size,
        batch_size = batch_siz,
        save_to_dir = save_to_dir,
        save_prefix  = val_image_folder,
        shuffle = shuffle,
        seed = seed)

    label_generator2 = label_datagen.flow_from_directory(
        image_root,
        classes = [val_mask_folder],
        class_mode = None,
        color_mode = label_color_mode,
        target_size = target_size,
        batch_size = batch_siz,
        save_to_dir = save_to_dir,
        save_prefix  = val_mask_folder,
        shuffle = shuffle,
        seed = seed)
    
    data_generator1 = zip(image_generator1, label_generator1)
    data_generator2 = zip(image_generator2, label_generator2)
    
    global steps___per_epochs
    steps___per_epochs = len(label_generator1)

    cnt = 0

    if mode == 'test' or mode == 'valid':
        for (img,label) in data_generator2:
            img,label = adjustData(img, label, 'complete', cnt)
            cnt+=img.shape[0]
            yield (img,label)

    else:
        while (True):
            for (img, label) in data_generator1:
                img, label = adjustData(img, label, 'complete', cnt, 'F')
                cnt += img.shape[0]
                yield (img, label)

trainset = dataset(mode='train')
validset = dataset(mode='valid')

input_img = Input((img_H, img_W,1), name='img')

# Model Load
# model = lit_net(input_img)
# model = u_model(input_img)

iiinputs = Input((img_H, img_W, 1))
model = MultiRes_litnet(iiinputs)

# model = u_net(input_img) # last one
# model = unet(input_img)
# model = model_s8(input_img)
model.summary()

# model_checkpoint = ModelCheckpoint(ckpt_path, monitor='val_loss', verbose=1, save_best_only=True)
model_checkpoint = ModelCheckpoint('drive/My Drive/skullMultiRes_litnet.h5', monitor='val_loss', verbose=1, save_best_only=True)

# Model Train
print('spe: ',steps___per_epochs)

model_json = model.to_json()
with open("drive/My Drive/skullMultiRes_litnet.json", "w") as json_file:
    json_file.write(model_json)

model.fit_generator(generator=trainset,
                    steps_per_epoch = steps___per_epochs,
                    epochs=epoch, verbose=1,
                    validation_data=validset,
                    validation_steps=steps___per_epochs*2,
                    shuffle=True,
                    callbacks=[model_checkpoint], use_multiprocessing=False ,workers=1)

# with open('drive/My Drive/skullMultiRes_litnet.json', 'r') as f:
#     old_model = model_from_json(f.read())

# old_model.load_weights('drive/My Drive/skullMultiRes_litnet.h5')
# # old_model.compile(optimizer=SGD(lr=0.01, nesterov=True), loss=dice_coef_loss, metrics=[dice_coef])
# old_model.compile(optimizer=Adam(lr=0.00001, decay=0.00001), loss=dice_coef_loss, metrics=[dice_coef])

# old_model.fit_generator(generator=trainset,
#                     steps_per_epoch = steps___per_epochs,
#                     epochs=epoch, verbose=1,
#                     validation_data=validset,
#                     validation_steps=steps___per_epochs*2,
#                     shuffle=True,
#                     callbacks=[model_checkpoint], use_multiprocessing=False ,workers=1)
